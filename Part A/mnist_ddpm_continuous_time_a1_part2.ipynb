{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This UNET-style prediction model was originally included as part of the Score-based generative modelling tutorial \n",
    "# by Yang Song et al: https://colab.research.google.com/drive/120kYYBOVa1i0TD85RjlEkFjaWDxSFUx3?usp=sharing\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "\n",
    "class GaussianFourierProjection(nn.Module):\n",
    "  \"\"\"Gaussian random features for encoding time steps.\"\"\"  \n",
    "  def __init__(self, embed_dim, scale=30.):\n",
    "    super().__init__()\n",
    "    # Randomly sample weights during initialization. These weights are fixed \n",
    "    # during optimization and are not trainable.\n",
    "    self.W = nn.Parameter(torch.randn(embed_dim // 2) * scale, requires_grad=False)\n",
    "  def forward(self, x):\n",
    "    x_proj = x[:, None] * self.W[None, :] * 2 * np.pi\n",
    "    return torch.cat([torch.sin(x_proj), torch.cos(x_proj)], dim=-1)\n",
    "\n",
    "\n",
    "class Dense(nn.Module):\n",
    "  \"\"\"A fully connected layer that reshapes outputs to feature maps.\"\"\"\n",
    "  def __init__(self, input_dim, output_dim):\n",
    "    super().__init__()\n",
    "    self.dense = nn.Linear(input_dim, output_dim)\n",
    "  def forward(self, x):\n",
    "    return self.dense(x)[..., None, None]\n",
    "\n",
    "\n",
    "class ScoreNet(nn.Module):\n",
    "  \"\"\"A time-dependent score-based model built upon U-Net architecture.\"\"\"\n",
    "\n",
    "  def __init__(self, marginal_prob_std, channels=[32, 64, 128, 256], embed_dim=256):\n",
    "    \"\"\"Initialize a time-dependent score-based network.\n",
    "\n",
    "    Args:\n",
    "      marginal_prob_std: A function that takes time t and gives the standard\n",
    "        deviation of the perturbation kernel p_{0t}(x(t) | x(0)).\n",
    "      channels: The number of channels for feature maps of each resolution.\n",
    "      embed_dim: The dimensionality of Gaussian random feature embeddings.\n",
    "    \"\"\"\n",
    "    super().__init__()\n",
    "    # Gaussian random feature embedding layer for time\n",
    "    self.embed = nn.Sequential(GaussianFourierProjection(embed_dim=embed_dim),\n",
    "         nn.Linear(embed_dim, embed_dim))\n",
    "    # Encoding layers where the resolution decreases\n",
    "    self.conv1 = nn.Conv2d(1, channels[0], 3, stride=1, bias=False)\n",
    "    self.dense1 = Dense(embed_dim, channels[0])\n",
    "    self.gnorm1 = nn.GroupNorm(4, num_channels=channels[0])\n",
    "    self.conv2 = nn.Conv2d(channels[0], channels[1], 3, stride=2, bias=False)\n",
    "    self.dense2 = Dense(embed_dim, channels[1])\n",
    "    self.gnorm2 = nn.GroupNorm(32, num_channels=channels[1])\n",
    "    self.conv3 = nn.Conv2d(channels[1], channels[2], 3, stride=2, bias=False)\n",
    "    self.dense3 = Dense(embed_dim, channels[2])\n",
    "    self.gnorm3 = nn.GroupNorm(32, num_channels=channels[2])\n",
    "    self.conv4 = nn.Conv2d(channels[2], channels[3], 3, stride=2, bias=False)\n",
    "    self.dense4 = Dense(embed_dim, channels[3])\n",
    "    self.gnorm4 = nn.GroupNorm(32, num_channels=channels[3])    \n",
    "\n",
    "    # Decoding layers where the resolution increases\n",
    "    self.tconv4 = nn.ConvTranspose2d(channels[3], channels[2], 3, stride=2, bias=False)\n",
    "    self.dense5 = Dense(embed_dim, channels[2])\n",
    "    self.tgnorm4 = nn.GroupNorm(32, num_channels=channels[2])\n",
    "    self.tconv3 = nn.ConvTranspose2d(channels[2] + channels[2], channels[1], 3, stride=2, bias=False, output_padding=1)    \n",
    "    self.dense6 = Dense(embed_dim, channels[1])\n",
    "    self.tgnorm3 = nn.GroupNorm(32, num_channels=channels[1])\n",
    "    self.tconv2 = nn.ConvTranspose2d(channels[1] + channels[1], channels[0], 3, stride=2, bias=False, output_padding=1)    \n",
    "    self.dense7 = Dense(embed_dim, channels[0])\n",
    "    self.tgnorm2 = nn.GroupNorm(32, num_channels=channels[0])\n",
    "    self.tconv1 = nn.ConvTranspose2d(channels[0] + channels[0], 1, 3, stride=1)\n",
    "    \n",
    "    # The swish activation function\n",
    "    self.act = lambda x: x * torch.sigmoid(x)\n",
    "    self.marginal_prob_std = marginal_prob_std\n",
    "  \n",
    "  def forward(self, x, t): \n",
    "    # Obtain the Gaussian random feature embedding for t   \n",
    "    embed = self.act(self.embed(t))    \n",
    "    # Encoding path\n",
    "    h1 = self.conv1(x)    \n",
    "    ## Incorporate information from t\n",
    "    h1 += self.dense1(embed)\n",
    "    ## Group normalization\n",
    "    h1 = self.gnorm1(h1)\n",
    "    h1 = self.act(h1)\n",
    "    h2 = self.conv2(h1)\n",
    "    h2 += self.dense2(embed)\n",
    "    h2 = self.gnorm2(h2)\n",
    "    h2 = self.act(h2)\n",
    "    h3 = self.conv3(h2)\n",
    "    h3 += self.dense3(embed)\n",
    "    h3 = self.gnorm3(h3)\n",
    "    h3 = self.act(h3)\n",
    "    h4 = self.conv4(h3)\n",
    "    h4 += self.dense4(embed)\n",
    "    h4 = self.gnorm4(h4)\n",
    "    h4 = self.act(h4)\n",
    "\n",
    "    # Decoding path\n",
    "    h = self.tconv4(h4)\n",
    "    ## Skip connection from the encoding path\n",
    "    h += self.dense5(embed)\n",
    "    h = self.tgnorm4(h)\n",
    "    h = self.act(h)\n",
    "    h = self.tconv3(torch.cat([h, h3], dim=1))\n",
    "    h += self.dense6(embed)\n",
    "    h = self.tgnorm3(h)\n",
    "    h = self.act(h)\n",
    "    h = self.tconv2(torch.cat([h, h2], dim=1))\n",
    "    h += self.dense7(embed)\n",
    "    h = self.tgnorm2(h)\n",
    "    h = self.act(h)\n",
    "    h = self.tconv1(torch.cat([h, h1], dim=1))\n",
    "\n",
    "    # Normalize output\n",
    "    h = h / self.marginal_prob_std(t)[:, None, None, None]\n",
    "    return h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import functools\n",
    "\n",
    "def marginal_prob_std(t, sigma):\n",
    "  \"\"\"Compute the mean and standard deviation of $p_{0t}(x(t) | x(0))$.\n",
    "\n",
    "  Args:    \n",
    "    t: A vector of time steps.\n",
    "    sigma: The sigma of the SDE. \n",
    "  \n",
    "  Returns:\n",
    "    The standard deviation.\n",
    "  \"\"\"    \n",
    "  t = torch.tensor(t, device=device)\n",
    "  return torch.sqrt((sigma**(2 * t) - 1.) / 2. / np.log(sigma))\n",
    "\n",
    "def diffusion_coeff(t, sigma):\n",
    "  \"\"\"Compute the diffusion coefficient of our SDE.\n",
    "\n",
    "  Args:\n",
    "    t: A vector of time steps.\n",
    "    sigma: The sigma of the SDE.\n",
    "  \n",
    "  Returns:\n",
    "    The vector of diffusion coefficients.\n",
    "  \"\"\"\n",
    "  return torch.tensor(sigma**t, device=device)\n",
    "  \n",
    "sigma =  25.0\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else \"mps\" if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "marginal_prob_std_fn = functools.partial(marginal_prob_std, sigma=sigma)\n",
    "diffusion_coeff_fn = functools.partial(diffusion_coeff, sigma=sigma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_fn(model, x, marginal_prob_std, eps=1e-5):\n",
    "  \"\"\"The loss function for training score-based generative models.\n",
    "\n",
    "  Args:\n",
    "    model: A PyTorch model instance that represents a \n",
    "      time-dependent score-based model.\n",
    "    x: A mini-batch of training data.    \n",
    "    marginal_prob_std: A function that gives the standard deviation of \n",
    "      the perturbation kernel.\n",
    "    eps: A tolerance value for numerical stability.\n",
    "  \"\"\"\n",
    "  random_t = torch.rand(x.shape[0], device=x.device) * (1. - eps) + eps  \n",
    "  z = torch.randn_like(x)\n",
    "  std = marginal_prob_std(random_t)\n",
    "  perturbed_x = x + z * std[:, None, None, None]\n",
    "  score = model(perturbed_x, random_t)\n",
    "  #loss is MSE between estimated score and true score as per Song 2021 eq 7\n",
    "  loss = torch.mean(torch.sum((score * std[:, None, None, None] + z)**2, dim=(1,2,3)))\n",
    "  return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###Sampler\n",
    "import tqdm\n",
    "\n",
    "def Euler_Maruyama_sampler(score_model, \n",
    "                           marginal_prob_std,\n",
    "                           diffusion_coeff, \n",
    "                           batch_size=64, \n",
    "                           num_steps=500, \n",
    "                           device='cuda', \n",
    "                           eps=1e-3):\n",
    "  \"\"\"Generate samples from score-based models with the Euler-Maruyama solver.\n",
    "\n",
    "  Args:\n",
    "    score_model: A PyTorch model that represents the time-dependent score-based model.\n",
    "    marginal_prob_std: A function that gives the standard deviation of\n",
    "      the perturbation kernel.\n",
    "    diffusion_coeff: A function that gives the diffusion coefficient of the SDE.\n",
    "    batch_size: The number of samplers to generate by calling this function once.\n",
    "    num_steps: The number of sampling steps. \n",
    "      Equivalent to the number of discretized time steps.\n",
    "    device: 'cuda' for running on GPUs, and 'cpu' for running on CPUs.\n",
    "    eps: The smallest time step for numerical stability.\n",
    "  \n",
    "  Returns:\n",
    "    Samples.    \n",
    "  \"\"\"\n",
    "  t = torch.ones(batch_size, device=device)\n",
    "  init_x = torch.randn(batch_size, 1, 28, 28, device=device) \\\n",
    "    * marginal_prob_std(t)[:, None, None, None]\n",
    "  time_steps = torch.linspace(1., eps, num_steps, device=device)\n",
    "  step_size = time_steps[0] - time_steps[1]\n",
    "  x = init_x\n",
    "  with torch.no_grad():\n",
    "    for time_step in tqdm.tqdm(time_steps):      \n",
    "      batch_time_step = torch.ones(batch_size, device=device) * time_step\n",
    "      g = diffusion_coeff(batch_time_step)\n",
    "      mean_x = x + (g**2)[:, None, None, None] * score_model(x, batch_time_step) * step_size\n",
    "      x = mean_x + torch.sqrt(step_size) * g[:, None, None, None] * torch.randn_like(x)      \n",
    "  # Do not include any noise in the last sampling step.\n",
    "  return mean_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import datasets, transforms, utils\n",
    "\n",
    "def reporter(mean_x):\n",
    "    \"\"\"Callback function used for plotting images during training\n",
    "    \n",
    "    Args:\n",
    "      mean_x: The generated samples from the Euler-Maruyama sampler.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    # Number of samples to plot\n",
    "    nsamples = 10\n",
    "\n",
    "    # Get samples\n",
    "    samples = mean_x[:nsamples].cpu().detach()\n",
    "\n",
    "    # print(samples.shape)\n",
    "    # print(samples)\n",
    "    \n",
    "    # Map pixel values back from [-1,1] to [0,1]\n",
    "    samples = (samples+1)/2 \n",
    "    samples = samples.clamp(0.0, 1.0)\n",
    "\n",
    "    # Plot in grid\n",
    "    grid = utils.make_grid(samples.reshape(-1, 1, 28, 28), nrow=nsamples)\n",
    "    plt.gca().set_axis_off()\n",
    "    plt.imshow(transforms.functional.to_pil_image(grid), cmap=\"gray\")\n",
    "    plt.show()   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.optim import Adam\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.datasets import MNIST\n",
    "from tqdm import trange  # Import tqdm for both epoch and batch progress\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Assuming ScoreNet, loss_fn, marginal_prob_std_fn, Euler_Maruyama_sampler, reporter, device are defined elsewhere\n",
    "\n",
    "# Initialize the model\n",
    "score_model = torch.nn.DataParallel(ScoreNet(marginal_prob_std=marginal_prob_std_fn))\n",
    "\n",
    "# score_model.load_state_dict(torch.load('continuous_diffusion_ckpt.pth'))\n",
    "score_model = score_model.to(device)\n",
    "\n",
    "# Training parameters\n",
    "n_epochs = 50\n",
    "batch_size = 64\n",
    "lr = 1e-3\n",
    "sampler_num_steps = 100\n",
    "\n",
    "# Data transformations\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(), \n",
    "    transforms.Lambda(lambda x: x + torch.rand(x.shape)/255),    # Dequantize pixel values\n",
    "    transforms.Lambda(lambda x: (x - 0.5) * 2.0),                # Map from [0,1] -> [-1, 1]\n",
    "    #transforms.Lambda(lambda x: x.flatten())\n",
    "])\n",
    "\n",
    "# Load the MNIST dataset\n",
    "dataloader_train = DataLoader(\n",
    "    MNIST('./mnist_data', download=True, train=True, transform=transform),\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "# Initialize the optimizer\n",
    "optimizer = Adam(score_model.parameters(), lr=lr)\n",
    "\n",
    "# Initialize the epoch progress bar\n",
    "tqdm_epoch = trange(n_epochs, desc='Training Progress', unit='epoch')\n",
    "\n",
    "for epoch in tqdm_epoch:\n",
    "    avg_loss = 0.0\n",
    "    num_items = 0\n",
    "    \n",
    "    # Optionally, add a nested progress bar for batches\n",
    "    for x, y in dataloader_train:\n",
    "        x = x.to(device)\n",
    "        loss = loss_fn(score_model, x, marginal_prob_std_fn)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        avg_loss += loss.item() * x.size(0)\n",
    "        num_items += x.size(0)\n",
    "    \n",
    "    # Calculate the average loss for the epoch\n",
    "    average_loss = avg_loss / num_items\n",
    "    \n",
    "    # Display using sampler every 2 epochs (adjusted from 10 to match your condition)\n",
    "    if epoch % 2 == 0:\n",
    "        sampler = Euler_Maruyama_sampler(\n",
    "            score_model, marginal_prob_std_fn, diffusion_coeff_fn, \n",
    "            batch_size=16, num_steps=sampler_num_steps, device=device\n",
    "        ) \n",
    "        # Show the generated images inline\n",
    "        reporter(sampler)\n",
    "    \n",
    "    # Update the checkpoint after each epoch of training\n",
    "    torch.save(score_model.state_dict(), 'continuous_diffusion_ckpt_p2.pth')\n",
    "    \n",
    "    # Update the progress bar with the average loss\n",
    "    tqdm_epoch.set_postfix({'Average Loss': f'{average_loss:.6f}'})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the model\n",
    "score_model = torch.nn.DataParallel(ScoreNet(marginal_prob_std=marginal_prob_std_fn))\n",
    "\n",
    "#load the model\n",
    "score_model.load_state_dict(torch.load('continuous_diffusion_model_ckpt.pth'))\n",
    "\n",
    "# score_model.load_state_dict(torch.load('continuous_diffusion_ckpt.pth'))\n",
    "score_model = score_model.to(device)\n",
    "\n",
    "# Data transformations\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(), \n",
    "    transforms.Lambda(lambda x: x + torch.rand(x.shape)/255),    # Dequantize pixel values\n",
    "    transforms.Lambda(lambda x: (x - 0.5) * 2.0),                # Map from [0,1] -> [-1, 1]\n",
    "    #transforms.Lambda(lambda x: x.flatten())\n",
    "])\n",
    "\n",
    "# Load the MNIST dataset\n",
    "dataloader_train = DataLoader(\n",
    "    MNIST('./mnist_data', download=True, train=True, transform=transform),\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "\n",
    "sampler = Euler_Maruyama_sampler(\n",
    "    score_model, marginal_prob_std_fn, diffusion_coeff_fn, \n",
    "    batch_size=1000, num_steps=100, device=device\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from metrics import calculate_inception_score_and_fid\n",
    "\n",
    "def evaluate(dataloader, sampler_generator, device, nsamples=10000):\n",
    "    \"\"\"\n",
    "    Evaluate model using Inception Score and FID\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    dataloader: utils.DataLoader\n",
    "        Pytorch dataloader\n",
    "    sampler_generator: function\n",
    "        Function that generates samples from the model\n",
    "    device: torch.device\n",
    "        Device to run the model on\n",
    "    nsamples: int\n",
    "        Number of samples to generate (must be less than batch size of dataloader and sampler_generator)\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    inception_mean: float\n",
    "        Inception Score mean\n",
    "    inception_std: float\n",
    "        Inception Score std\n",
    "    FID: float\n",
    "        FID score\n",
    "    \"\"\"\n",
    "    batch_size = dataloader.batch_size\n",
    "\n",
    "    # Generate samples\n",
    "    samples = sampler_generator[:nsamples].to(device)\n",
    "    \n",
    "    # Map pixel values back from [-1,1] to [0,1]\n",
    "    samples = (samples+1)/2 \n",
    "    samples = samples.clamp(0.0, 1.0)\n",
    "\n",
    "    generated_samples = samples.reshape(-1, 1, 28, 28)\n",
    "\n",
    "    real_samples = []\n",
    "    for x, _ in dataloader:\n",
    "        real_samples.append(x.reshape(-1, 1, 28, 28))\n",
    "        if len(real_samples)*batch_size >= nsamples:\n",
    "            break\n",
    "    real_samples = torch.cat(real_samples, dim=0)[:nsamples].to(device)\n",
    "\n",
    "    #add 3 channels to generated and real samples\n",
    "    generated_samples = torch.cat([generated_samples, generated_samples, generated_samples], dim=1)\n",
    "    real_samples = torch.cat([real_samples, real_samples, real_samples], dim=1)\n",
    "\n",
    "    print(generated_samples.shape)\n",
    "    print(real_samples.shape)\n",
    "\n",
    "    #convert to float tensor\n",
    "    generated_samples = generated_samples.float()\n",
    "    real_samples = real_samples.float()\n",
    "\n",
    "    # Calculate Inception Score and FID\n",
    "    inception_mean, inception_std, FID =  calculate_inception_score_and_fid(\n",
    "    generated_samples,\n",
    "    real_samples,\n",
    "    batch_size=32,\n",
    "    device=device,\n",
    "    resize=True,\n",
    "    )\n",
    "\n",
    "    return inception_mean, inception_std, FID\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "incep_mean, incep_std, fid = evaluate(dataloader_train, sampler, device, nsamples=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "incep_mean, incep_std, fid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PML",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
